"""
Musubi Tuner FLUX Klein LoRA Training Config Template

Generates TOML dataset configuration files for flux_2_train_network.py
Supports both FLUX Klein 4B and 9B variants.
"""

import os


def generate_dataset_config(
    image_folder: str,
    resolution: int = 960,
    batch_size: int = 1,
    enable_bucket: bool = True,
    num_repeats: int = 10,
) -> str:
    """
    Generate a TOML dataset config file for Musubi Tuner FLUX Klein training.

    Args:
        num_repeats: How many times to repeat each image per epoch.
                     Higher = fewer epochs for same step count, less overhead.
    Returns the config as a TOML string.
    """

    # Escape backslashes for TOML on Windows
    image_folder_escaped = image_folder.replace('\\', '/')

    config = f'''# Musubi Tuner FLUX Klein Dataset Config
# Generated by ComfyUI Musubi FLUX Klein LoRA Trainer

[general]
resolution = [{resolution}, {resolution}]
batch_size = {batch_size}
enable_bucket = {str(enable_bucket).lower()}
caption_extension = ".txt"

[[datasets]]
image_directory = "{image_folder_escaped}"
num_repeats = {num_repeats}
'''

    return config


def save_config(config_content: str, config_path: str):
    """Save config content to a TOML file."""
    with open(config_path, 'w', encoding='utf-8') as f:
        f.write(config_content)


# FLUX Klein variant configurations
# Note: We use the "Base" (non-distilled) variants which are recommended for training
# Distilled variants (klein-4b, klein-9b) are not recommended for LoRA training
FLUX_KLEIN_VARIANTS = {
    "Klein Base 4B": {
        "model_version": "klein-base-4b",
        "text_encoder_hint": "Qwen3-4B",
        "max_blocks_to_swap": 13,
    },
    "Klein Base 9B": {
        "model_version": "klein-base-9b",
        "text_encoder_hint": "Qwen3-8B",
        "max_blocks_to_swap": 16,
    },
}


# VRAM mode presets for FLUX Klein (Musubi Tuner)
# Uses fp8_text_encoder (NOT fp8_llm) for text encoder quantization
# Max blocks_to_swap depends on variant: 13 for 4B, 16 for 9B
MUSUBI_FLUX_KLEIN_VRAM_PRESETS = {
    "Max (1256px)": {
        "optimizer": "adamw8bit",
        "mixed_precision": "bf16",
        "batch_size": 1,
        "gradient_checkpointing": False,
        "fp8_scaled": False,
        "fp8_text_encoder": False,
        "blocks_to_swap": 0,
        "resolution": 1256,
    },
    "Max (1256px) fp8": {
        "optimizer": "adamw8bit",
        "mixed_precision": "bf16",
        "batch_size": 1,
        "gradient_checkpointing": False,
        "fp8_scaled": True,
        "fp8_text_encoder": True,
        "blocks_to_swap": 0,
        "resolution": 1256,
    },
    "Max (1256px) fp8 offload": {
        "optimizer": "adamw8bit",
        "mixed_precision": "bf16",
        "batch_size": 1,
        "gradient_checkpointing": True,
        "fp8_scaled": True,
        "fp8_text_encoder": True,
        "blocks_to_swap": 8,
        "resolution": 1256,
    },
    "Medium (1024px)": {
        "optimizer": "adamw8bit",
        "mixed_precision": "bf16",
        "batch_size": 1,
        "gradient_checkpointing": True,
        "fp8_scaled": False,
        "fp8_text_encoder": False,
        "blocks_to_swap": 0,
        "resolution": 1024,
    },
    "Medium (1024px) fp8": {
        "optimizer": "adamw8bit",
        "mixed_precision": "bf16",
        "batch_size": 1,
        "gradient_checkpointing": True,
        "fp8_scaled": True,
        "fp8_text_encoder": True,
        "blocks_to_swap": 0,
        "resolution": 1024,
    },
    "Medium (1024px) fp8 offload": {
        "optimizer": "adamw8bit",
        "mixed_precision": "bf16",
        "batch_size": 1,
        "gradient_checkpointing": True,
        "fp8_scaled": True,
        "fp8_text_encoder": True,
        "blocks_to_swap": 8,
        "resolution": 1024,
    },
    "Low (768px)": {
        "optimizer": "adamw8bit",
        "mixed_precision": "bf16",
        "batch_size": 1,
        "gradient_checkpointing": True,
        "fp8_scaled": True,
        "fp8_text_encoder": True,
        "blocks_to_swap": 10,
        "resolution": 768,
    },
    "Min (512px)": {
        "optimizer": "adamw8bit",
        "mixed_precision": "bf16",
        "batch_size": 1,
        "gradient_checkpointing": True,
        "fp8_scaled": True,
        "fp8_text_encoder": True,
        "blocks_to_swap": 13,  # Max for 4B, will be adjusted for 9B
        "resolution": 512,
    },
}
